

```markdown
# Tarea 3 â€“ Procesamiento de Datos con Apache Spark

Este repositorio contiene el desarrollo de la **Tarea 3** del curso **Procesamiento de Datos con Apache Spark**, en la que se implementa una soluciÃ³n completa de anÃ¡lisis de datos en **modo batch y streaming** utilizando **Apache Spark** y **Apache Kafka**.

## ğŸ“ Estructura del repositorio

```
/codigo/
  â”œâ”€â”€ tarea3.py                   # Script para procesamiento batch de datos histÃ³ricos
  â”œâ”€â”€ spark_streaming_consumer.py # Script de consumo en tiempo real desde Kafka usando Spark Structured Streaming
  â””â”€â”€ README.md                   # Documento actual
```

---

## ğŸ§  Objetivo general

Implementar una soluciÃ³n distribuida de procesamiento de datos que permita analizar informaciÃ³n en batch y en tiempo real, integrando Apache Spark con Apache Kafka.

---

## ğŸš€ TecnologÃ­as utilizadas

- Apache Spark 3.4.4
- Apache Kafka 3.7.2
- Python 3.10
- Spark Structured Streaming
- Kafka-python
- VirtualizaciÃ³n: UTM en macOS (Ubuntu 22.04)
- Herramientas: Spark Web UI, CLI, SSH, SCP

---

## ğŸ“„ DescripciÃ³n de scripts

### `tarea3.py`  
Procesamiento batch de un archivo CSV con datos de la Tasa de Cambio Representativa del Mercado (TRM).  
âœ”ï¸ Limpieza de datos  
âœ”ï¸ VisualizaciÃ³n de estadÃ­sticas  
âœ”ï¸ Transformaciones bÃ¡sicas con DataFrame API

### `spark_streaming_consumer.py`  
Procesamiento de datos en tiempo real desde Kafka.  
âœ”ï¸ Consumo desde topic `sensor_data`  
âœ”ï¸ Lectura de JSON y deserializaciÃ³n  
âœ”ï¸ Ventanas de agregaciÃ³n por sensor  
âœ”ï¸ VisualizaciÃ³n por consola con `writeStream`

---

## ğŸ§ª CÃ³mo ejecutar

### ğŸ”¹ Procesamiento batch

```bash
spark-submit tarea3.py
```

### ğŸ”¹ Streaming desde Kafka

1. Iniciar Zookeeper y Kafka Broker:
```bash
$KAFKA_HOME/bin/zookeeper-server-start.sh config/zookeeper.properties &
$KAFKA_HOME/bin/kafka-server-start.sh config/server.properties &
```

2. Ejecutar el consumidor:
```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3 \
  spark_streaming_consumer.py
```

3. Visualizar en: [http://localhost:4040](http://localhost:4040)

---

## ğŸ“¸ Evidencias del proceso

Capturas disponibles en el informe y presentaciÃ³n:

- Jobs y Stages ejecutados
- Panel de ejecuciÃ³n en Structured Streaming
- Consola de resultados por ventana temporal
- MÃ©tricas en tiempo real

---

## ğŸ“š Referencias

Consulta las referencias formales en el [informe acadÃ©mico PDF](../Informe_Tarea3_Spark.pdf).

---

## ğŸ‘¨â€ğŸ’» Autor

**Adrian Ramirez** â€“ Estudiante de IngenierÃ­a de Sistemas  
UNAD â€“ Abril 2025

---


